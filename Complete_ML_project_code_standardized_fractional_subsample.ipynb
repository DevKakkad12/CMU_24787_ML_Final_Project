{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"name":"Copy of Complete_ML_project_code_standardized.ipynb","provenance":[{"file_id":"1QGTltS0hICk4xvXNI0XUR1Oedsxzq61f","timestamp":1638811556655}],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"YuSfao1PN7xC"},"source":["### Imports"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QHffkFzcvXIZ","executionInfo":{"status":"ok","timestamp":1638844767784,"user_tz":300,"elapsed":19318,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}},"outputId":"e9a500f3-aa54-4db8-f074-7c2e3d52f9a7"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"cBnaAwyVN7xF","executionInfo":{"status":"ok","timestamp":1638844770999,"user_tz":300,"elapsed":3219,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["import numpy as np\n","\n","# Add models here\n","from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.feature_selection import mutual_info_classif\n","from sklearn.feature_selection import SelectKBest\n","from sklearn import svm\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import CategoricalNB\n","from sklearn.pipeline import Pipeline\n","from tensorflow import keras\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras import optimizers\n","\n","# Sklearn imports for processing and evaluation\n","from sklearn.decomposition import PCA\n","from sklearn.metrics import median_absolute_error, accuracy_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","# Plotting\n","from matplotlib import pyplot as plt\n","\n","# Misc\n","import time\n","from tqdm import tqdm"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XUwP6IpUN7xG"},"source":["### Load Data"]},{"cell_type":"code","metadata":{"id":"pzC3UFcNN7xG","executionInfo":{"status":"ok","timestamp":1638844779306,"user_tz":300,"elapsed":8309,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["x_train = np.loadtxt(\"/content/drive/MyDrive/uci_har_dataset/train/X_train.txt\")\n","y_train = np.loadtxt(\"/content/drive/MyDrive/uci_har_dataset/train/y_train.txt\")\n","\n","x_test = np.loadtxt(\"/content/drive/MyDrive/uci_har_dataset/test/X_test.txt\")\n","y_test = np.loadtxt(\"/content/drive/MyDrive/uci_har_dataset/test/y_test.txt\")"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZDT8sEf5N7xG"},"source":["### Combine Data"]},{"cell_type":"code","metadata":{"id":"e_UTcf3BN7xG","executionInfo":{"status":"ok","timestamp":1638844779306,"user_tz":300,"elapsed":10,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["combined_x = np.concatenate((x_train, x_test))\n","combined_y = np.concatenate((y_train, y_test))\n","\n","assert combined_x.shape[0] == x_train.shape[0] + x_test.shape[0]\n","assert combined_y.shape[0] == y_train.shape[0] + y_test.shape[0]"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5iTwnhnoN7xH"},"source":["### Baseline model"]},{"cell_type":"markdown","metadata":{"id":"OyHVg4FgbqcU"},"source":["#### Neural Network"]},{"cell_type":"code","metadata":{"id":"3f_Pm_i5N7xH","executionInfo":{"status":"ok","timestamp":1638844779306,"user_tz":300,"elapsed":9,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["def do_kfoldNN(x_data, y_data, features='all', folds=10):\n","    start = time.time()\n","    # Do KFold\n","    kf = KFold(folds)\n","    \n","    # KF training\n","    pred_accuracy = []\n","    fit_times = []\n","    for idx, (train_idx, test_idx) in tqdm(enumerate(kf.split(x_data))):    \n","        \n","        # Do PCA\n","        features = x_data.shape[1] if(features == 'all') else features\n","        pca = PCA(n_components=features)\n","        scalar = StandardScaler().fit(x_data[train_idx])\n","        standardized = scalar.transform(x_data[train_idx])\n","        transformed = pca.fit_transform(standardized)\n","        \n","        # Fit and time model\n","        \n","        x = x_data[train_idx].astype('float32')\n","        n_features = x_data[train_idx].shape[1]\n","        k1 = transformed.shape[1]\n","        print(k1)\n","        model = Sequential()\n","        model.add(Dense(k1, activation='relu', kernel_initializer='he_normal', input_shape=(k1,)))\n","        model.add(Dense(384, activation='relu',  kernel_initializer='he_normal'))\n","        model.add(Dense(6,activation='softmax'))\n","        \n","        optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,name='Adam')\n","        \n","        model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","        print(transformed.shape, y_data[train_idx.shape])\n","        #raise\n","        print(np.unique(y_data[train_idx]))\n","        model.fit(transformed, y_data[train_idx], batch_size = 30, epochs = 5)\n","        # Transform test data and evaluate\n","        test_transform = np.dot(scalar.transform(x_data[test_idx]), pca.components_.T)\n","        preds = model.predict(test_transform)\n","        #print(preds)\n","        #print(y_data[test_idx])\n","        loss, score = model.evaluate(test_transform, y_data[test_idx], verbose=0)\n","        #score = accuracy_score(preds, y_data[test_idx])\n","        pred_accuracy.append(score)\n","        fit_times.append(time.time() - start)\n","        \n","    print(r\"{0} FEATURES PREDICTION ACCURACY: {1:.3f} $\\pm$ {2:.3f}\".format(features, np.mean(pred_accuracy), np.std(pred_accuracy)))\n","    return pred_accuracy, fit_times"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":503},"id":"XdAV5OPNN7xI","executionInfo":{"status":"error","timestamp":1638844785869,"user_tz":300,"elapsed":6572,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}},"outputId":"639ba4ac-dfeb-4c4f-f55e-8310dbf200d2"},"source":["#for i in range (0,len(combined_y)):\n","#    combined_y[i] = combined_y[i]-1\n","\n","combined_y_mod = combined_y - 1\n","pred_accuracyNN, fit_timesNN = do_kfoldNN(combined_x, combined_y_mod, features=561)\n","\n","scores_nn = np.mean(pred_accuracyNN)\n","scores_nn_std = np.std(pred_accuracyNN)\n","time_nn = np.mean(fit_timesNN)\n","\n","np.save(\"/content/drive/MyDrive/uci_har_dataset/results/nn_score.npy\", pred_accuracyNN)\n","np.save(\"/content/drive/MyDrive/uci_har_dataset/results/nn_time.npy\", fit_timesNN)\n","\n","print(f\"The accuracy is {np.mean(scores_nn)*100:1.3f}% with a standard deviation of {scores_nn_std:1.3f}\")\n","print(f\"The time taken to complete the model is {time_nn:1.2f}s\")"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["561\n","(9269, 561) 3.0\n","[0. 1. 2. 3. 4. 5.]\n","Epoch 1/5\n","309/309 [==============================] - 2s 6ms/step - loss: 0.1590 - accuracy: 0.9429\n","Epoch 2/5\n","284/309 [==========================>...] - ETA: 0s - loss: 0.0426 - accuracy: 0.9852"]},{"output_type":"stream","name":"stderr","text":["\r0it [00:05, ?it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-f75b1d5a9254>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcombined_y_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_y\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpred_accuracyNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_timesNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_kfoldNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_y_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m561\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mscores_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_accuracyNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-a2f1bee542c8>\u001b[0m in \u001b[0;36mdo_kfoldNN\u001b[0;34m(x_data, y_data, features, folds)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Transform test data and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mtest_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1209\u001b[0m             with tf.profiler.experimental.Trace(\n\u001b[1;32m   1210\u001b[0m                 \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1248\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m       \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m       can_run_full_execution = (\n\u001b[1;32m   1252\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    643\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    647\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msparse_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m   \u001b[0;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_handle_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   4063\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4064\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 4065\u001b[0;31m         _ctx, \"Identity\", name, input)\n\u001b[0m\u001b[1;32m   4066\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4067\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"2UOh080DCDZ0"},"source":["#### CV Code"]},{"cell_type":"code","metadata":{"id":"sGNcT5L8CEjb","executionInfo":{"status":"aborted","timestamp":1638844785646,"user_tz":300,"elapsed":255,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["def do_kfold(model, x_data, y_data, folds=10, seed=1):\n","         \n","    # Do KFold\n","    kf = KFold(folds)\n","    np.random.seed(seed)\n","    \n","    # KF training\n","    pred_accuracy = []\n","    fit_times = []\n","    for idx, (train_idx, test_idx) in tqdm(enumerate(kf.split(list(range(len(y_data)))))): \n","\n","        scalar = StandardScaler().fit(x_data[train_idx])\n","        standardized = scalar.transform(x_data[train_idx])\n","\n","        # Fit and time model\n","        start = time.time()\n","        model.fit(standardized, y_data[train_idx])\n","        fit_times.append(time.time() - start)\n","        \n","        # Score model\n","        preds = model.predict(scalar.transform(x_data[test_idx]))\n","        score = accuracy_score(preds, y_data[test_idx])\n","        pred_accuracy.append(score)\n","        \n","    print(r\"{0} POINTS PREDICTION ACCURACY: {1:.3f} $\\pm$ {2:.3f}\".format(len(y_data), np.mean(pred_accuracy), np.std(pred_accuracy)))\n","    return pred_accuracy, fit_times"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"soKvthFtN7xJ"},"source":["#### Logistic Regression"]},{"cell_type":"code","metadata":{"id":"gCGM2cjyN7xJ","executionInfo":{"status":"aborted","timestamp":1638844785646,"user_tz":300,"elapsed":255,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["# prepare the cross-validation procedure\n","t0 = time.time()\n","cv = KFold(n_splits=10)\n","# create model\n","model = LogisticRegression(multi_class='ovr', solver='liblinear')\n","# evaluate model\n","scaler = StandardScaler()\n","pipeline = Pipeline([('transformer', scaler), ('estimator', model)])\n","#scores = cross_val_score(pipeline, combined_x, combined_y, scoring='accuracy', cv=cv)\n","\n","scores, times = do_kfold(model, combined_x, combined_y)\n","scores_lr = np.mean(scores)\n","scores_lr_std = np.std(scores)\n","#print(f\"The accuracy is {np.mean(scores_lr)*100:1.3f}% with a standard deviation of {np.std(scores_lr):1.3f}\")\n","#t1 = time.time()\n","#t1 = time.time()\n","#time_lg = t1 - t0\n","#print(f\"The time taken to complete the model is {time_lg:1.2f}s\")\n","\n","np.save(\"/content/drive/MyDrive/uci_har_dataset/results/lr_score.npy\", scores)\n","np.save(\"/content/drive/MyDrive/uci_har_dataset/results/lr_time.npy\", times)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MsgGd68NN7xJ"},"source":["#### SVM Linear"]},{"cell_type":"code","metadata":{"id":"_FvCz9OVN7xJ","executionInfo":{"status":"aborted","timestamp":1638844785647,"user_tz":300,"elapsed":256,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["tsvm_0 = time.time()\n","cv = KFold(n_splits=10)\n","# create model\n","model = svm.SVC(kernel='linear', C=1)\n","# evaluate model\n","#scaler = StandardScaler()\n","#pipeline = Pipeline([('transformer', scaler), ('estimator', model)])\n","#scores = cross_val_score(pipeline, combined_x, combined_y, scoring='accuracy', cv=cv)\n","#scores_svm_linear = np.mean(scores)\n","#scores_svm_linear_std = np.std(scores)\n","scores, times = do_kfold(model, combined_x, combined_y)\n","\n","\n","#print(f\"The accuracy is {np.mean(scores_svm_linear)*100:1.3f}% with a standard deviation of {scores_svm_linear_std:1.3f}\")\n","#tsvm_1 = time.time()\n","#time_svm_linear = tsvm_1 - tsvm_0\n","#print(f\"The time taken to complete the model is {time_svm_linear:1.2f}s\")\n","\n","np.save(\"/content/drive/MyDrive/uci_har_dataset/results/lin_score.npy\", scores)\n","np.save(\"/content/drive/MyDrive/uci_har_dataset/results/lin_time.npy\", times)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KprHB0LDN7xJ"},"source":["#### SVM Poly"]},{"cell_type":"code","metadata":{"id":"DBjt_Ln2N7xK","executionInfo":{"status":"aborted","timestamp":1638844785647,"user_tz":300,"elapsed":256,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["tsvm_0 = time.time()\n","cv = KFold(n_splits=10)\n","# create model\n","model = svm.SVC(kernel='poly', C=1)\n","# evaluate model\n","#scaler = StandardScaler()\n","#pipeline = Pipeline([('transformer', scaler), ('estimator', model)])\n","#scores = cross_val_score(pipeline, combined_x, combined_y, scoring='accuracy', cv=cv)\n","#scores_svm_linear = np.mean(scores)\n","#scores_svm_linear_std = np.std(scores)\n","scores, times = do_kfold(model, combined_x, combined_y)\n","\n","\n","#print(f\"The accuracy is {np.mean(scores_svm_linear)*100:1.3f}% with a standard deviation of {scores_svm_linear_std:1.3f}\")\n","#tsvm_1 = time.time()\n","#time_svm_linear = tsvm_1 - tsvm_0\n","#print(f\"The time taken to complete the model is {time_svm_linear:1.2f}s\")\n","\n","np.save(\"/content/drive/MyDrive/uci_har_dataset/results/poly_score.npy\", scores)\n","np.save(\"/content/drive/MyDrive/uci_har_dataset/results/poly_time.npy\", times)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LCYaGcD-N7xK"},"source":["#### Random Forest"]},{"cell_type":"code","metadata":{"id":"aIT949a2N7xK","executionInfo":{"status":"aborted","timestamp":1638844785647,"user_tz":300,"elapsed":256,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["trf_0 = time.time()\n","cv = KFold(n_splits=5)\n","# create model\n","model = RandomForestClassifier()\n","# evaluate model\n","#scaler = StandardScaler()\n","#pipeline = Pipeline([('transformer', scaler), ('estimator', model)])\n","#scores = cross_val_score(pipeline, combined_x, combined_y, scoring='accuracy', cv=cv)\n","#scores_svm_poly = np.mean(scores)\n","#scores_rf = np.mean(scores)\n","#scores_rf_std = np.std(scores)\n","scores, times = do_kfold(model, combined_x, combined_y)\n","\n","#print(f\"The accuracy is {scores_rf*100:1.3f}% with a standard deviation of {scores_rf_std:1.3f}\")\n","#trf_1 = time.time()\n","#time_rf = trf_1 - trf_0\n","#print(f\"The time taken to complete the model is {time_rf:1.2f}s\")\n","\n","np.save(\"/content/drive/MyDrive/uci_har_dataset/results/rf_score.npy\", scores)\n","np.save(\"/content/drive/MyDrive/uci_har_dataset/results/rf_time.npy\", times)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HnvmyaI7N7xK"},"source":["#### Gradient Boost"]},{"cell_type":"code","metadata":{"id":"O_nR1Q3dN7xK","executionInfo":{"status":"aborted","timestamp":1638844785647,"user_tz":300,"elapsed":256,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["tgb_0 = time.time()\n","cv = KFold(n_splits=5)\n","# create model\n","model = GradientBoostingClassifier()\n","# evaluate model\n","scaler = StandardScaler()\n","pipeline = Pipeline([('transformer', scaler), ('estimator', model)])\n","#scores = cross_val_score(pipeline, combined_x, combined_y, scoring='accuracy', cv=cv)\n","#scores_svm_poly = np.mean(scores)\n","#scores_gb = np.mean(scores)\n","#scores_gb_std = np.std(scores)\n","\n","#print(f\"The accuracy is {scores_gb*100:1.3f}% with a standard deviation of {scores_gb_std:1.3f}\")\n","#tgb_1 = time.time()\n","\n","#tgb_1 = time.time()\n","#time_gb = tgb_1 - tgb_0\n","#print(f\"The time taken to complete the model is {time_gb:1.2f}s\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9TsgZGlzN7xK"},"source":["#### Plots comparing accuracy and time to run the alogrithms"]},{"cell_type":"code","metadata":{"id":"mR8v6f3DN7xK","executionInfo":{"status":"aborted","timestamp":1638844785648,"user_tz":300,"elapsed":9,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["#run_time = np.array([time_lg, time_svm_linear, time_svm_poly, time_rf, time_nn, time_gb])\n","#accuracies =  np.array([scores_lr, scores_svm_linear, scores_svm_poly, scores_rf, scores_nn, scores_gb])\n","#accuracy_std = np.array([scores_lr_std, scores_svm_linear_std, scores_svm_poly_std, scores_rf_std, scores_nn_std, scores_gb_std])\n","#name_models = ['Log Reg', 'Linear SVM', 'Poly SVM','Rand For', 'Neural Nets', 'Gradient Boost']\n","\n","name_model_wgb = ['Log Reg', 'Linear SVM', 'Poly SVM','Rand For', 'Neural Nets']\n","accuracies_wgb =  np.array([scores_lr, scores_svm_linear, scores_svm_poly, scores_rf, scores_nn])\n","accuracy_std_wgb = np.array([scores_lr_std, scores_svm_linear_std, scores_svm_poly_std, scores_rf_std, scores_nn_std])\n","run_time_wgb = np.array([time_lg, time_svm_linear, time_svm_poly, time_rf, time_nn])\n","\n","#plt.figure\n","#plt.bar(name_models, run_time)\n","#plt.title('Time taken to run alogrithm')\n","#plt.ylabel('Time (sec)')\n","#plt.show()\n","\n","plt.figure\n","plt.bar(name_model_wgb, run_time_wgb)\n","plt.title('Time taken to run alogrithms without Gradient Boost')\n","plt.ylabel('Time (sec)')\n","plt.show()\n","\n","#plt.figure\n","#plt.bar(name_models, accuracies, yerr=accuracy_std)\n","#plt.title('Baseline accuracies of each alogrithm')\n","#plt.ylabel('Accuracy')\n","#plt.show()\n","\n","plt.figure\n","plt.bar(name_model_wgb, accuracies_wgb, yerr=accuracy_std_wgb)\n","plt.title('Baseline accuracies without Gradient Boost')\n","plt.ylabel('Accuracy')\n","plt.show()\n","\n","plt.plot(time_lg,scores_lr, 'ro', label = 'Logistic Regression')\n","plt.plot(time_svm_linear,scores_svm_linear, 'bo', label = 'Linear SVM')\n","plt.plot(time_svm_poly,scores_svm_poly, 'go', label = 'Poly SVM')\n","plt.plot(time_rf,scores_rf, 'yo', label = 'Random Forest')\n","plt.plot(time_nn,scores_nn, 'ko', label = 'Neural Network')\n","#plt.plot(time_gb,scores_gb, 'mo', label = 'Gradient Boost')\n","plt.xlabel('Time ')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e0cGOTIXN7xL"},"source":["## Part 2\n","### Comparing feature selection and feature extraction"]},{"cell_type":"markdown","metadata":{"id":"9IRn_4DpN7xL"},"source":["### Feature selection using probabilistic mutual information"]},{"cell_type":"code","metadata":{"id":"nP9HpPZRN7xL","executionInfo":{"status":"aborted","timestamp":1638844785648,"user_tz":300,"elapsed":9,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["def do_kfold_mutual_info(model, x_data, y_data, features='all', folds=10):\n","     \n","    # Do KFold\n","    kf = KFold(folds)\n","    \n","    # KF training\n","    pred_accuracy = []\n","    fit_times = []\n","    for idx, (train_idx, test_idx) in tqdm(enumerate(kf.split(x_data))):    \n","        \n","        # Do Mutual Information Feature Extraction\n","        features = x_data.shape[1] if(features == 'all') else features\n","        fs = SelectKBest(score_func=mutual_info_classif, k=features)\n","        fs.fit(x_data[train_idx], y_data[train_idx])\n","        x_train_fs = fs.transform(x_data[train_idx])\n","        x_test_fs = fs.transform(x_data[test_idx])\n","\n","        # Standardize data\n","        scaler = StandardScaler().fit(x_train_fs)\n","        transformed = scaler.transform(x_train_fs)\n","        \n","        # Fit and time model\n","        start = time.time()\n","        model.fit(transformed, y_data[train_idx])\n","        fit_times.append(time.time() - start)\n","        \n","        # Transform test data and evaluate\n","\n","        preds = model.predict(scaler.transform(x_test_fs))\n","        score = accuracy_score(preds, y_data[test_idx])\n","        pred_accuracy.append(score)\n","        \n","    print(r\"{0} FEATURES PREDICTION ACCURACY: {1:.3f} $\\pm$ {2:.3f}\".format(features, np.mean(pred_accuracy), np.std(pred_accuracy)))\n","    return pred_accuracy, fit_times"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iCDZ68DeN7xL"},"source":["### Training for Different Number of Mutual information"]},{"cell_type":"code","metadata":{"id":"uV6HnYzpN7xL","executionInfo":{"status":"aborted","timestamp":1638844785648,"user_tz":300,"elapsed":9,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["# Number of PCA Components\n","num_features = np.arange(5, 500, 20)\n","\n","results = []\n","times = []\n","for features in num_features:\n","    print(features)\n","    pred_accuracy, fit_times = do_kfold_mutual_info(svm.SVC(kernel='linear', C=1), combined_x, combined_y, features=features)\n","    results.append(pred_accuracy)\n","    times.append(fit_times)\n","\n","# Get means\n","ml_acc_mean = np.mean(results, axis=1)\n","ml_acc_stds = np.std(results, axis=1)\n","ml_time_mean = np.mean(times, axis=1)\n","ml_time_stds = np.std(times, axis=1)\n","\n","\"/content/drive/MyDrive/uci_har_dataset/test/X_test.txt\"\n","np.save(\"/content/drive/MyDrive/uci_har_dataset/svm_linear_results.npy\", results)\n","np.save(\"/content/drive/MyDrive/uci_har_dataset/mi_results/svm_linear_time.npy\", times)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PNGuCVlX8INR","executionInfo":{"status":"aborted","timestamp":1638844785648,"user_tz":300,"elapsed":9,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["!zip -r pca_results.zip pca_results/\n","!zip -r subsampled_results.zip subsampled_results/\n","!zip -r mi_results.zip mi_results/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PX_YstKgN7xL"},"source":["### Feature extraction using PCA"]},{"cell_type":"code","metadata":{"id":"bHi2-5o_N7xL","executionInfo":{"status":"aborted","timestamp":1638844785648,"user_tz":300,"elapsed":9,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["def do_kfold_pca(model, x_data, y_data, features='all', folds=10):\n","     \n","    # Do KFold\n","    kf = KFold(folds)\n","    \n","    # KF training\n","    pred_accuracy = []\n","    fit_times = []\n","    for idx, (train_idx, test_idx) in tqdm(enumerate(kf.split(x_data))):    \n","        \n","        # Do PCA\n","        start = time.time()\n","        features = x_data.shape[1] if(features == 'all') else features\n","        pca = PCA(n_components=features)\n","        scalar = StandardScaler().fit(x_data[train_idx])\n","        standardized = scalar.transform(x_data[train_idx])\n","        transformed = pca.fit_transform(x_data[train_idx])\n","        \n","        # Fit and time model\n","        model.fit(transformed, y_data[train_idx])\n","        fit_times.append(time.time() - start)\n","        \n","        # Transform test data and evaluate\n","        test_transform = np.dot(scalar.transform(x_data[test_idx]), pca.components_.T)\n","        #test_transform = np.dot(x_data[test_idx], pca.components_.T)\n","        preds = model.predict(test_transform)\n","        score = accuracy_score(preds, y_data[test_idx])\n","        pred_accuracy.append(score)\n","        \n","    print(r\"{0} FEATURES PREDICTION ACCURACY: {1:.3f} $\\pm$ {2:.3f}\".format(features, np.mean(pred_accuracy), np.std(pred_accuracy)))\n","    return pred_accuracy, fit_times"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-UwgmoyYN7xL","executionInfo":{"status":"aborted","timestamp":1638844785648,"user_tz":300,"elapsed":9,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["num_features = np.arange(5, 500, 20)\n","results = []\n","times = []\n","for features in num_features:\n","    pred_accuracy, fit_times = do_kfold_pca(svm.SVC(kernel='linear', C=1), combined_x, combined_y, features=features)\n","    results.append(pred_accuracy)\n","    times.append(fit_times)\n","\n","# Get means\n","pca_acc_mean = np.mean(results, axis=1)\n","pca_acc_stds = np.std(results, axis=1)\n","pca_time_mean = np.mean(times, axis=1)\n","pca_time_stds = np.std(times, axis=1)\n","\n","np.save(\"/content/drive/MyDrive/uci_har_dataset/results/lin_pre_pca_score.npy\", results)\n","np.save(\"/content/drive/MyDrive/uci_har_dataset/results/lin_pre_pca_time.npy\", times)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VV_U_RSCN7xM"},"source":["### Psuedo Data"]},{"cell_type":"code","metadata":{"id":"vrS3zsujN7xM","executionInfo":{"status":"aborted","timestamp":1638844785649,"user_tz":300,"elapsed":10,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["def do_kfold_psudodata(model, x_data, y_data, num_points=500, folds=10, seed=1):\n","         \n","    # Do KFold\n","    kf = KFold(folds)\n","    \n","    # KF training\n","    pred_accuracy = []\n","    fit_times = []\n","    \n","    np.random.seed(seed)\n","    \n","    for idx, (train_idx, test_idx) in tqdm(enumerate(kf.split(list(range(len(y_data)))))): \n","        \n","        # Get mean and std for each label\n","        x_1 = combined_x[train_idx][np.argwhere(combined_y[train_idx] == 0)[:,0]]\n","        x_2 = combined_x[train_idx][np.argwhere(combined_y[train_idx] == 1)[:,0]]\n","        x_3 = combined_x[train_idx][np.argwhere(combined_y[train_idx] == 2)[:,0]]\n","        x_4 = combined_x[train_idx][np.argwhere(combined_y[train_idx] == 3)[:,0]]\n","        x_5 = combined_x[train_idx][np.argwhere(combined_y[train_idx] == 4)[:,0]]\n","        x_6 = combined_x[train_idx][np.argwhere(combined_y[train_idx] == 5)[:,0]]\n","\n","        mean_1 = np.mean(x_1, axis=0)\n","        std_1 = np.std(x_1, axis=0)\n","        mean_2 = np.mean(x_2, axis=0)\n","        std_2 = np.std(x_2, axis=0)\n","        mean_3 = np.mean(x_3, axis=0)\n","        std_3 = np.std(x_3, axis=0)\n","        mean_4 = np.mean(x_4, axis=0)\n","        std_4 = np.std(x_4, axis=0)\n","        mean_5 = np.mean(x_5, axis=0)\n","        std_5 = np.std(x_5, axis=0)\n","        mean_6 = np.mean(x_6, axis=0)\n","        std_6 = np.std(x_6, axis=0)\n","    \n","        # Sample Pseudodata\n","        sampled_x1 = np.random.multivariate_normal(mean_1, std_1*np.eye(len(std_1)), num_points)\n","        sampled_x2 = np.random.multivariate_normal(mean_2, std_2*np.eye(len(std_2)), num_points)\n","        sampled_x3 = np.random.multivariate_normal(mean_3, std_3*np.eye(len(std_3)), num_points)\n","        sampled_x4 = np.random.multivariate_normal(mean_4, std_4*np.eye(len(std_4)), num_points)\n","        sampled_x5 = np.random.multivariate_normal(mean_5, std_5*np.eye(len(std_5)), num_points)\n","        sampled_x6 = np.random.multivariate_normal(mean_6, std_6*np.eye(len(std_6)), num_points)\n","\n","        # Combine pseudodata\n","        sampled_combined = np.concatenate([sampled_x1, sampled_x2, sampled_x3, sampled_x4, sampled_x5, sampled_x6])\n","\n","        # Get labels\n","        labels = np.ones(len(sampled_combined))\n","        for i in range(1,7):\n","            labels[(i-1)*num_points:(i)*num_points] *= i\n","\n","        # Fit and time model\n","        start = time.time()\n","        model.fit(sampled_combined, labels)\n","        fit_times.append(time.time() - start)\n","        \n","        # Score model\n","        preds = model.predict(x_data[test_idx])\n","        score = accuracy_score(preds, y_data[test_idx])\n","        pred_accuracy.append(score)\n","        \n","    print(r\"{0} POINTS PREDICTION ACCURACY: {1:.3f} $\\pm$ {2:.3f}\".format(num_points, np.mean(pred_accuracy), np.std(pred_accuracy)))\n","    return pred_accuracy, fit_times"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mCX8-e-zN7xM","executionInfo":{"status":"aborted","timestamp":1638844785649,"user_tz":300,"elapsed":9,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["# Number of Psuedo data points\n","num_points =np.arange(5, 500, 20)\n","\n","results = []\n","times = []\n","for num in num_points:\n","    pred_accuracy, fit_times = do_kfold_psudodata(svm.SVC(kernel='linear', C=1), combined_x, combined_y, num_points=num)\n","    results.append(pred_accuracy)\n","    times.append(fit_times)\n","    \n","# Get means\n","psd_acc_mean = np.mean(results, axis=1)\n","psd_acc_stds = np.std(results, axis=1)\n","psd_time_mean = np.mean(times, axis=1)\n","psd_time_stds = np.std(times, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GYaixrz9N7xM","executionInfo":{"status":"aborted","timestamp":1638844785649,"user_tz":300,"elapsed":9,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["# Plot prediction accuracies\n","fig, ax = plt.subplots()\n","ax.plot(num_features, pca_acc_mean, label= 'PCA')\n","ax.plot(num_features, ml_acc_mean, label = 'Mutual Information')\n","# ax.plot(num_features, psd_acc_mean, label = 'Psuedo Data')\n","ax.fill_between(num_features, ml_acc_mean+ml_acc_stds, ml_acc_mean-ml_acc_stds, alpha=0.3)\n","ax.fill_between(num_features, pca_acc_mean+pca_acc_stds, pca_acc_mean-pca_acc_stds, alpha=0.3)\n","# ax.fill_between(num_features, psd_acc_mean+psd_acc_stds, psd_acc_mean-psd_acc_stds, alpha=0.3)\n","ax.set(title=\"Prediction Accuracies\", xlabel=\"Number of Features\", ylabel=\"Prediction Acciracy\")\n","plt.legend()\n","plt.show()\n","\n","# Plot timing\n","fig, ax = plt.subplots()\n","ax.plot(num_features, pca_time_mean, label= 'PCA')\n","ax.fill_between(num_features, pca_time_mean+pca_time_stds, pca_time_mean-pca_time_stds, alpha=0.3)\n","ax.plot(num_features, ml_time_mean, label = 'Mutual Information')\n","ax.fill_between(num_features, ml_time_mean+ml_time_stds, ml_time_mean-ml_time_stds, alpha=0.3)\n","ax.plot(num_features, psd_time_mean, label = 'Psuedo Data')\n","ax.fill_between(num_features, psd_time_mean+psd_time_stds, psd_time_mean-psd_time_stds, alpha=0.3)\n","ax.set(title=\"Training Time\", xlabel=\"Number of Features\", ylabel=\"Time (s)\")\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NAlNyxrrO-Ob"},"source":["### Subsampled Data"]},{"cell_type":"code","metadata":{"id":"_MmfuEPdN7xM","executionInfo":{"status":"aborted","timestamp":1638844785649,"user_tz":300,"elapsed":9,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["def do_kfold_subsampled(model, x_data, y_data, num_points=100, folds=10, seed=1):\n","         \n","    # Do KFold\n","    kf = KFold(folds)\n","    \n","    np.random.seed(seed)\n","    \n","    # KF training\n","    pred_accuracy = []\n","    fit_times = []\n","    for idx, (train_idx, test_idx) in tqdm(enumerate(kf.split(list(range(len(y_data)))))): \n","        \n","        # Get idxs of each label\n","        idx_1 = np.argwhere(combined_y[train_idx] == 1)[:,0]\n","        idx_2 = np.argwhere(combined_y[train_idx] == 2)[:,0]\n","        idx_3 = np.argwhere(combined_y[train_idx] == 3)[:,0]\n","        idx_4 = np.argwhere(combined_y[train_idx] == 4)[:,0]\n","        idx_5 = np.argwhere(combined_y[train_idx] == 5)[:,0]\n","        idx_6 = np.argwhere(combined_y[train_idx] == 6)[:,0]\n","        \n","        # Randomly sample num_points from each index\n","        idx1 = np.random.choice(idx_1, num_points)\n","        idx2 = np.random.choice(idx_2, num_points)\n","        idx3 = np.random.choice(idx_3, num_points)\n","        idx4 = np.random.choice(idx_4, num_points)\n","        idx5 = np.random.choice(idx_5, num_points)\n","        idx6 = np.random.choice(idx_6, num_points)\n","    \n","        # Sample data\n","        sampled_x1 = x_data[train_idx][idx1]\n","        sampled_x2 = x_data[train_idx][idx2]\n","        sampled_x3 = x_data[train_idx][idx3]\n","        sampled_x4 = x_data[train_idx][idx4]\n","        sampled_x5 = x_data[train_idx][idx5]\n","        sampled_x6 = x_data[train_idx][idx6]\n","\n","        # Combine subsampled data\n","        sampled_combined = np.concatenate([sampled_x1, sampled_x2, sampled_x3, sampled_x4, sampled_x5, sampled_x6])\n","\n","        # Get labels\n","        labels = np.ones(len(sampled_combined))\n","        for i in range(1,7):\n","            labels[(i-1)*num_points:(i)*num_points] *= i\n","\n","        # Fit and time model\n","        start = time.time()\n","        model.fit(sampled_combined, labels)\n","        fit_times.append(time.time() - start)\n","        \n","        # Score model\n","        preds = model.predict(x_data[test_idx])\n","        score = accuracy_score(preds, y_data[test_idx])\n","        pred_accuracy.append(score)\n","        \n","    print(r\"{0} POINTS PREDICTION ACCURACY: {1:.3f} $\\pm$ {2:.3f}\".format(num_points, np.mean(pred_accuracy), np.std(pred_accuracy)))\n","    return pred_accuracy, fit_times"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"GzduSll9N7xM","executionInfo":{"status":"aborted","timestamp":1638844785649,"user_tz":300,"elapsed":9,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["# Number of Psuedo data points\n","num_points =np.arange(5, 500, 20)\n","\n","results = []\n","times = []\n","for num in num_points:\n","    pred_accuracy, fit_times = do_kfold_subsampled(svm.SVC(kernel='linear', C=1), combined_x, combined_y, num_points=num)\n","    results.append(pred_accuracy)\n","    times.append(fit_times)\n","    \n","# Get means\n","sub_acc_mean = np.mean(results, axis=1)\n","sub_acc_stds = np.std(results, axis=1)\n","sub_time_mean = np.mean(times, axis=1)\n","sub_time_stds = np.std(times, axis=1)\n","\n","np.save(\"./subsampled_results/svm_linear_accuracy.npy\", results)\n","np.save(\"./subsampled_results/svm_linear_time.npy\", times)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"alSi9NCVN7xM","executionInfo":{"status":"aborted","timestamp":1638844785649,"user_tz":300,"elapsed":9,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["fig, ax = plt.subplots()\n","ax.plot(num_points, sub_acc_mean)\n","ax.fill_between(num_points, sub_acc_mean+sub_acc_stds, sub_acc_mean-sub_acc_stds, alpha=0.5)\n","plt.show()\n","\n","fig, ax = plt.subplots()\n","ax.plot(num_points, sub_time_mean)\n","ax.fill_between(num_points, sub_time_mean+sub_time_stds, sub_time_mean-sub_time_stds, alpha=0.5)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ze0zhvhTN7xM","executionInfo":{"status":"aborted","timestamp":1638844785649,"user_tz":300,"elapsed":9,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["# Number of Psuedo data points\n","num_points =np.arange(5, 500, 20)\n","\n","results = []\n","times = []\n","for num in num_points:\n","    pred_accuracy, fit_times = do_kfold_subsampled(svm.SVC(kernel='poly', C=1), combined_x, combined_y, num_points=num)\n","    results.append(pred_accuracy)\n","    times.append(fit_times)\n","    \n","# Get means\n","sub_acc_mean = np.mean(results, axis=1)\n","sub_acc_stds = np.std(results, axis=1)\n","sub_time_mean = np.mean(times, axis=1)\n","sub_time_stds = np.std(times, axis=1)\n","\n","np.save(\"./subsampled_results/svm_poly_accuracy.npy\", results)\n","np.save(\"./subsampled_results/svm_poly_time.npy\", times)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fw1AuSqDN7xN","executionInfo":{"status":"aborted","timestamp":1638844785650,"user_tz":300,"elapsed":10,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["fig, ax = plt.subplots()\n","ax.plot(num_points, sub_acc_mean)\n","ax.fill_between(num_points, sub_acc_mean+sub_acc_stds, sub_acc_mean-sub_acc_stds, alpha=0.5)\n","plt.show()\n","\n","fig, ax = plt.subplots()\n","ax.plot(num_points, sub_time_mean)\n","ax.fill_between(num_points, sub_time_mean+sub_time_stds, sub_time_mean-sub_time_stds, alpha=0.5)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"hea87FprN7xN","executionInfo":{"status":"aborted","timestamp":1638844785650,"user_tz":300,"elapsed":10,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["# Number of Psuedo data points\n","num_points =np.arange(5, 500, 20)\n","\n","results = []\n","times = []\n","for num in num_points:\n","    pred_accuracy, fit_times = do_kfold_subsampled(LogisticRegression(multi_class='ovr', solver='liblinear'), combined_x, combined_y, num_points=num)\n","    results.append(pred_accuracy)\n","    times.append(fit_times)\n","    \n","# Get means\n","sub_acc_mean = np.mean(results, axis=1)\n","sub_acc_stds = np.std(results, axis=1)\n","sub_time_mean = np.mean(times, axis=1)\n","sub_time_stds = np.std(times, axis=1)\n","\n","np.save(\"./subsampled_results/lr_accuracy.npy\", pred_accuracy)\n","np.save(\"./subsampled_results/lr_time.npy\", fit_times)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NrYTXhClN7xN","executionInfo":{"status":"aborted","timestamp":1638844785650,"user_tz":300,"elapsed":10,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["fig, ax = plt.subplots()\n","ax.plot(num_points, sub_acc_mean)\n","ax.fill_between(num_points, sub_acc_mean+sub_acc_stds, sub_acc_mean-sub_acc_stds, alpha=0.5)\n","plt.show()\n","\n","fig, ax = plt.subplots()\n","ax.plot(num_points, sub_time_mean)\n","ax.fill_between(num_points, sub_time_mean+sub_time_stds, sub_time_mean-sub_time_stds, alpha=0.5)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"iXCxq842N7xN","executionInfo":{"status":"aborted","timestamp":1638844785650,"user_tz":300,"elapsed":10,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["# Number of Psuedo data points\n","num_points =np.arange(5, 500, 20)\n","\n","results = []\n","times = []\n","for num in num_points:\n","    pred_accuracy, fit_times = do_kfold_subsampled(RandomForestClassifier(), combined_x, combined_y, num_points=num)\n","    results.append(pred_accuracy)\n","    times.append(fit_times)\n","    \n","# Get means\n","sub_acc_mean = np.mean(results, axis=1)\n","sub_acc_stds = np.std(results, axis=1)\n","sub_time_mean = np.mean(times, axis=1)\n","sub_time_stds = np.std(times, axis=1)\n","\n","np.save(\"./subsampled_results/rf_accuracy.npy\", pred_accuracy)\n","np.save(\"./subsampled_results/rf_time.npy\", fit_times)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0nGaKyLaPY87"},"source":["### Fractional Subsample"]},{"cell_type":"code","metadata":{"id":"8_1OO4ZLPcJm","executionInfo":{"status":"aborted","timestamp":1638844785650,"user_tz":300,"elapsed":10,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["def do_kfold_frac_subsampled(model, x_data, y_data, sample_frac=0.1, folds=10, seed=1):\n","         \n","    # Do KFold\n","    kf = KFold(folds)\n","    np.random.seed(seed)\n","    \n","    # KF training\n","    pred_accuracy = []\n","    fit_times = []\n","    for idx, (train_idx, test_idx) in tqdm(enumerate(kf.split(list(range(len(y_data)))))): \n","        \n","        # Sample idx\n","        start = time.time()\n","        sample_idx = np.random.choice(range(len(train_idx)), size=int(len(train_idx)*sample_frac))\n","\n","        sampled_combined = x_data[train_idx][sample_idx]\n","        labels = y_data[train_idx][sample_idx]\n","\n","        scalar = StandardScaler().fit(sampled_combined)\n","        standardized = scalar.transform(sampled_combined)\n","\n","        # Fit and time model\n","        model.fit(standardized, labels)\n","        fit_times.append(time.time() - start)\n","        \n","        # Score model\n","        preds = model.predict(scalar.transform(x_data[test_idx]))\n","        score = accuracy_score(preds, y_data[test_idx])\n","        pred_accuracy.append(score)\n","        \n","    print(r\"{0} FRAC  {1} POINTS PREDICTION ACCURACY: {2:.3f} $\\pm$ {3:.3f}\".format(sample_frac, len(sample_idx), np.mean(pred_accuracy), np.std(pred_accuracy)))\n","    return pred_accuracy, fit_times"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hLB69zafau3r"},"source":["#### SVM Linear"]},{"cell_type":"code","metadata":{"id":"_yFu-F7-QIje","executionInfo":{"status":"aborted","timestamp":1638844785650,"user_tz":300,"elapsed":10,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["# Number of Psuedo data points\n","num_points = [0.001, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.075, 0.1, 0.125, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5]\n","\n","results = []\n","times = []\n","for num in num_points:\n","    pred_accuracy, fit_times = do_kfold_frac_subsampled(svm.SVC(kernel='linear', C=1), combined_x, combined_y, sample_frac=num)\n","    results.append(pred_accuracy)\n","    times.append(fit_times)\n","    \n","# Get means\n","sub_acc_mean = np.mean(results, axis=1)\n","sub_acc_stds = np.std(results, axis=1)\n","sub_time_mean = np.mean(times, axis=1)\n","sub_time_stds = np.std(times, axis=1)\n","\n","np.save(\"/content/drive/MyDrive/uci_har_dataset/results/svm_pre_sub_linear_accuracy.npy\", results)\n","np.save(\"/content/drive/MyDrive/uci_har_dataset/results/svm_pre_sub_linear_time.npy\", times)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cYDhz_ECTOkJ","executionInfo":{"status":"aborted","timestamp":1638844785650,"user_tz":300,"elapsed":10,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["fig, ax = plt.subplots()\n","ax.plot(num_points, sub_acc_mean)\n","ax.fill_between(num_points, sub_acc_mean+sub_acc_stds, sub_acc_mean-sub_acc_stds, alpha=0.5)\n","plt.show()\n","\n","fig, ax = plt.subplots()\n","ax.plot(num_points, sub_time_mean)\n","ax.fill_between(num_points, sub_time_mean+sub_time_stds, sub_time_mean-sub_time_stds, alpha=0.5)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jkMMKGJ_awu1"},"source":["#### SVM Poly"]},{"cell_type":"code","metadata":{"id":"xPudSOIzU9rw","executionInfo":{"status":"aborted","timestamp":1638844785650,"user_tz":300,"elapsed":10,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["# Number of Psuedo data points\n","num_points = [0.001, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.075, 0.1, 0.125, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5]\n","\n","results = []\n","times = []\n","for num in num_points:\n","    pred_accuracy, fit_times = do_kfold_frac_subsampled(svm.SVC(kernel='poly', C=1), combined_x, combined_y, sample_frac=num)\n","    results.append(pred_accuracy)\n","    times.append(fit_times)\n","    \n","# Get means\n","sub_acc_mean = np.mean(results, axis=1)\n","sub_acc_stds = np.std(results, axis=1)\n","sub_time_mean = np.mean(times, axis=1)\n","sub_time_stds = np.std(times, axis=1)\n","\n","np.save(\"./subsampled_results/svm_poly_accuracy.npy\", results)\n","np.save(\"./subsampled_results/svm_poly_time.npy\", times)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H_0F5UIdVDpv","executionInfo":{"status":"aborted","timestamp":1638844785650,"user_tz":300,"elapsed":10,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["fig, ax = plt.subplots()\n","ax.plot(num_points, sub_acc_mean)\n","ax.fill_between(num_points, sub_acc_mean+sub_acc_stds, sub_acc_mean-sub_acc_stds, alpha=0.5)\n","plt.show()\n","\n","fig, ax = plt.subplots()\n","ax.plot(num_points, sub_time_mean)\n","ax.fill_between(num_points, sub_time_mean+sub_time_stds, sub_time_mean-sub_time_stds, alpha=0.5)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Oyd3JXKaydZ"},"source":["#### Logistic Regression"]},{"cell_type":"code","metadata":{"id":"S7mInwzbWJf8","executionInfo":{"status":"aborted","timestamp":1638844785651,"user_tz":300,"elapsed":11,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["# Number of Psuedo data points\n","num_points = [0.001, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.075, 0.1, 0.125, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5]\n","\n","results = []\n","times = []\n","for num in num_points:\n","    pred_accuracy, fit_times = do_kfold_frac_subsampled(LogisticRegression(multi_class='ovr', solver='liblinear'), combined_x, combined_y, sample_frac=num)\n","    results.append(pred_accuracy)\n","    times.append(fit_times)\n","    \n","# Get means\n","sub_acc_mean = np.mean(results, axis=1)\n","sub_acc_stds = np.std(results, axis=1)\n","sub_time_mean = np.mean(times, axis=1)\n","sub_time_stds = np.std(times, axis=1)\n","\n","np.save(\"./subsampled_results/lr_accuracy.npy\", results)\n","np.save(\"./subsampled_results/lr_time.npy\", times)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zpYBGYZUWlEV","executionInfo":{"status":"aborted","timestamp":1638844785651,"user_tz":300,"elapsed":11,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["fig, ax = plt.subplots()\n","ax.plot(num_points, sub_acc_mean)\n","ax.fill_between(num_points, sub_acc_mean+sub_acc_stds, sub_acc_mean-sub_acc_stds, alpha=0.5)\n","plt.show()\n","\n","fig, ax = plt.subplots()\n","ax.plot(num_points, sub_time_mean)\n","ax.fill_between(num_points, sub_time_mean+sub_time_stds, sub_time_mean-sub_time_stds, alpha=0.5)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LA08kXILa1Jk"},"source":["#### Random Forest"]},{"cell_type":"code","metadata":{"id":"UcvrrW_fWzTt","executionInfo":{"status":"aborted","timestamp":1638844785651,"user_tz":300,"elapsed":10,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["# Number of Psuedo data points\n","num_points = [0.001, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.075, 0.1, 0.125, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5]\n","\n","results = []\n","times = []\n","for num in num_points:\n","    pred_accuracy, fit_times = do_kfold_frac_subsampled(RandomForestClassifier(), combined_x, combined_y, sample_frac=num)\n","    results.append(pred_accuracy)\n","    times.append(fit_times)\n","    \n","# Get means\n","sub_acc_mean = np.mean(results, axis=1)\n","sub_acc_stds = np.std(results, axis=1)\n","sub_time_mean = np.mean(times, axis=1)\n","sub_time_stds = np.std(times, axis=1)\n","\n","np.save(\"./subsampled_results/rf_accuracy.npy\", results)\n","np.save(\"./subsampled_results/rf_time.npy\", times)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JjJwBr7jarxC"},"source":["#### NN"]},{"cell_type":"code","metadata":{"id":"c41vg2L7as5H","executionInfo":{"status":"aborted","timestamp":1638844785651,"user_tz":300,"elapsed":10,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["def do_kfold_nn_frac_subsampled(model, x_data, y_data, sample_frac=0.1, folds=10, seed=1):\n","         \n","    # Do KFold\n","    kf = KFold(folds)\n","    np.random.seed(seed)\n","    \n","    # KF training\n","    pred_accuracy = []\n","    fit_times = []\n","    for idx, (train_idx, test_idx) in tqdm(enumerate(kf.split(list(range(len(y_data)))))): \n","        \n","        # Sample idx\n","        sample_idx = np.random.choice(range(len(train_idx)), size=int(len(train_idx)*sample_frac))\n","\n","        sampled_combined = x_data[train_idx][sample_idx].astype('float32')\n","        labels = y_data[train_idx][sample_idx]\n","\n","        # Fit and time model\n","        start = time.time()\n","        print(labels.shape)\n","        model.fit(sampled_combined, labels, batch_size = 30, epochs = 5)\n","\n","        fit_times.append(time.time() - start)\n","        \n","        # Score model\n","        #preds = model.predict(x_data[test_idx])\n","        #score = accuracy_score(preds, y_data[test_idx])\n","        loss, score = model.evaluate(x_data[test_idx], y_data[test_idx], verbose=0)\n","        pred_accuracy.append(score)\n","        \n","    print(r\"{0} FRAC  {1} POINTS PREDICTION ACCURACY: {2:.3f} $\\pm$ {3:.3f}\".format(sample_frac, len(sample_idx), np.mean(pred_accuracy), np.std(pred_accuracy)))\n","    return pred_accuracy, fit_times"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8T43sflPaJWy","executionInfo":{"status":"aborted","timestamp":1638844785651,"user_tz":300,"elapsed":10,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["# Number of Psuedo data points\n","num_points = [0.001, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.075, 0.1, 0.125, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5]\n","\n","results = []\n","times = []\n","for num in num_points:\n","    model = Sequential()\n","    model.add(Dense(561, activation='relu', kernel_initializer='he_normal', input_shape=(561,)))\n","    model.add(Dense(384, activation='relu',  kernel_initializer='he_normal'))\n","    model.add(Dense(6,activation='softmax'))\n","        \n","    optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,name='Adam')\n","        \n","    model.compile(optimizer='Adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","    #model.fit(transformed, y_data[train_idx], batch_size = 30, epochs = 5)\n","\n","    print(combined_x.shape)\n","    pred_accuracy, fit_times = do_kfold_nn_frac_subsampled(model, combined_x, combined_y-1, sample_frac=num)\n","    results.append(pred_accuracy)\n","    times.append(fit_times)\n","    \n","# Get means\n","sub_acc_mean = np.mean(results, axis=1)\n","sub_acc_stds = np.std(results, axis=1)\n","sub_time_mean = np.mean(times, axis=1)\n","sub_time_stds = np.std(times, axis=1)\n","\n","np.save(\"./subsampled_results/nn_accuracy.npy\", results)\n","np.save(\"./subsampled_results/nn_time.npy\", times)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aYQnkLsCYA1v","executionInfo":{"status":"aborted","timestamp":1638844785651,"user_tz":300,"elapsed":10,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["svm_lin = np.load(\"./subsampled_results/svm_linear_accuracy.npy\")\n","lin_mean = np.mean(svm_lin, axis=1)\n","lin_std = np.std(svm_lin, axis=1)\n","\n","svm_poly = np.load(\"./subsampled_results/svm_poly_accuracy.npy\")\n","poly_mean = np.mean(svm_poly, axis=1)\n","poly_std = np.std(svm_poly, axis=1)\n","\n","lr = np.load(\"./subsampled_results/lr_accuracy.npy\")\n","lr_mean = np.mean(lr, axis=1)\n","lr_std = np.std(lr, axis=1)\n","\n","rf = np.load(\"./subsampled_results/rf_accuracy.npy\")\n","rf_mean = np.mean(rf, axis=1)\n","rf_std = np.std(rf, axis=1)\n","\n","nn = np.load(\"./subsampled_results/nn_accuracy.npy\")\n","nn_mean = np.mean(nn, axis=1)\n","nn_std = np.std(nn, axis=1)\n","\n","\n","fig, ax = plt.subplots()\n","ax.plot(num_points, lin_mean, label=\"SVM Linear\")\n","ax.fill_between(num_points, lin_mean+lin_std, lin_mean-lin_std, alpha=0.3)\n","\n","ax.plot(num_points, poly_mean, label=\"SVM Poly\")\n","ax.fill_between(num_points, poly_mean+poly_std, poly_mean-poly_std, alpha=0.3)\n","\n","ax.plot(num_points, np.mean(lr, axis=1), label=\"Logistic Regression\")\n","ax.fill_between(num_points, lr_mean+lr_std, lr_mean-lr_std, alpha=0.3)\n","\n","ax.plot(num_points, np.mean(rf, axis=1), label=\"Random Forest\")\n","ax.fill_between(num_points, rf_mean+rf_std, rf_mean-rf_std, alpha=0.3)\n","\n","ax.plot(num_points, np.mean(nn, axis=1), label=\"Neural Network\")\n","ax.fill_between(num_points, nn_mean+nn_std, nn_mean-nn_std, alpha=0.3)\n","\n","ax.set(ylim=(0.9, 0.97))\n","ax.legend(loc='best')\n","ax.set(xlabel=\"Fraction of Data Used in Training\", ylabel=\"Prediction Accuracy\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3ZGjq_HMjyF8","executionInfo":{"status":"aborted","timestamp":1638844785651,"user_tz":300,"elapsed":10,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["svm_lin = np.load(\"./subsampled_results/svm_linear_time.npy\")\n","lin_mean = np.mean(svm_lin, axis=1)\n","lin_std = np.std(svm_lin, axis=1)\n","\n","svm_poly = np.load(\"./subsampled_results/svm_poly_time.npy\")\n","poly_mean = np.mean(svm_poly, axis=1)\n","poly_std = np.std(svm_poly, axis=1)\n","\n","lr = np.load(\"./subsampled_results/lr_time.npy\")\n","lr_mean = np.mean(lr, axis=1)\n","lr_std = np.std(lr, axis=1)\n","\n","rf = np.load(\"./subsampled_results/rf_time.npy\")\n","rf_mean = np.mean(rf, axis=1)\n","rf_std = np.std(rf, axis=1)\n","\n","nn = np.load(\"./subsampled_results/nn_time.npy\")\n","nn_mean = np.mean(nn, axis=1)\n","nn_std = np.std(nn, axis=1)\n","\n","\n","fig, ax = plt.subplots()\n","ax.plot(num_points, lin_mean, label=\"SVM Linear\")\n","ax.fill_between(num_points, lin_mean+lin_std, lin_mean-lin_std, alpha=0.3)\n","\n","ax.plot(num_points, poly_mean, label=\"SVM Poly\")\n","ax.fill_between(num_points, poly_mean+poly_std, poly_mean-poly_std, alpha=0.3)\n","\n","ax.plot(num_points, np.mean(lr, axis=1), label=\"Logistic Regression\")\n","ax.fill_between(num_points, lr_mean+lr_std, lr_mean-lr_std, alpha=0.3)\n","\n","ax.plot(num_points, np.mean(rf, axis=1), label=\"Random Forest\")\n","ax.fill_between(num_points, rf_mean+rf_std, rf_mean-rf_std, alpha=0.3)\n","\n","ax.plot(num_points, np.mean(nn, axis=1), label=\"Neural Network\")\n","ax.fill_between(num_points, nn_mean+nn_std, nn_mean-nn_std, alpha=0.3)\n","\n","ax.legend(loc='best')\n","ax.set(xlabel=\"Fraction of Data Used in Training\", ylabel=\"Training Time\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Prltds0ylKmI"},"source":["#### Plot for 'Ideal' Parameters"]},{"cell_type":"code","metadata":{"id":"olxnZiiflQLd","executionInfo":{"status":"aborted","timestamp":1638844785651,"user_tz":300,"elapsed":10,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["svm_lin = np.load(\"./subsampled_results/svm_linear_accuracy.npy\")\n","lin_mean = np.mean(svm_lin, axis=1)\n","lin_std = np.std(svm_lin, axis=1)\n","\n","svm_poly = np.load(\"./subsampled_results/svm_poly_accuracy.npy\")\n","poly_mean = np.mean(svm_poly, axis=1)\n","poly_std = np.std(svm_poly, axis=1)\n","\n","lr = np.load(\"./subsampled_results/lr_accuracy.npy\")\n","lr_mean = np.mean(lr, axis=1)\n","lr_std = np.std(lr, axis=1)\n","\n","rf = np.load(\"./subsampled_results/rf_accuracy.npy\")\n","rf_mean = np.mean(rf, axis=1)\n","rf_std = np.std(rf, axis=1)\n","\n","nn = np.load(\"./subsampled_results/nn_accuracy.npy\")\n","nn_mean = np.mean(nn, axis=1)\n","nn_std = np.std(nn, axis=1)\n","\n","svm_lintime = np.load(\"./subsampled_results/svm_linear_time.npy\")\n","lin_meantime = np.mean(svm_lintime, axis=1)\n","lin_stdtime = np.std(svm_lintime, axis=1)\n","\n","svm_polytime = np.load(\"./subsampled_results/svm_poly_time.npy\")\n","poly_meantime = np.mean(svm_polytime, axis=1)\n","poly_stdtime = np.std(svm_polytime, axis=1)\n","\n","lrtime = np.load(\"./subsampled_results/lr_time.npy\")\n","lr_meantime = np.mean(lrtime, axis=1)\n","lr_stdtime = np.std(lrtime, axis=1)\n","\n","rftime = np.load(\"./subsampled_results/rf_time.npy\")\n","rf_meantime = np.mean(rftime, axis=1)\n","rf_stdtime = np.std(rftime, axis=1)\n","\n","nntime = np.load(\"./subsampled_results/nn_time.npy\")\n","nn_meantime = np.mean(nntime, axis=1)\n","nn_stdtime = np.std(nntime, axis=1)\n","\n","best_idx = np.where(np.array(num_points)==0.25)\n","fig, ax = plt.subplots()\n","ax.scatter(lin_meantime[best_idx], lin_mean[best_idx])\n","ax.errorbar(lin_meantime[best_idx], lin_mean[best_idx], xerr=lin_stdtime[best_idx], yerr=lin_std[best_idx], capsize=3, fmt=\"none\")\n","\n","ax.scatter(poly_meantime[best_idx], poly_mean[best_idx])\n","ax.errorbar(poly_meantime[best_idx], poly_mean[best_idx], xerr=poly_stdtime[best_idx], yerr=poly_std[best_idx], capsize=3, fmt=\"none\")\n","\n","ax.scatter(lr_meantime[best_idx], lr_mean[best_idx])\n","ax.errorbar(lr_meantime[best_idx], lr_mean[best_idx], xerr=lr_stdtime[best_idx], yerr=lr_std[best_idx], capsize=3, fmt=\"none\")\n","\n","ax.scatter(rf_meantime[best_idx], rf_mean[best_idx])\n","ax.errorbar(rf_meantime[best_idx], rf_mean[best_idx], xerr=rf_stdtime[best_idx], yerr=rf_std[best_idx], capsize=3, fmt=\"none\")\n","\n","ax.scatter(nn_meantime[best_idx], nn_mean[best_idx])\n","ax.errorbar(nn_meantime[best_idx], nn_mean[best_idx], xerr=nn_stdtime[best_idx], yerr=nn_std[best_idx], capsize=3, fmt=\"none\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b4JZh-MhrwZm"},"source":["### Subsampled with PCA"]},{"cell_type":"code","metadata":{"id":"X2Mr32MKr0EN","executionInfo":{"status":"aborted","timestamp":1638844785652,"user_tz":300,"elapsed":11,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["def do_kfold_frac_subsampled_pca(model, x_data, y_data, sample_frac=0.1, features=20, folds=10, seed=1):\n","         \n","    # Do KFold\n","    kf = KFold(folds)\n","    np.random.seed(seed)\n","    \n","    # KF training\n","    pred_accuracy = []\n","    fit_times = []\n","    for idx, (train_idx, test_idx) in tqdm(enumerate(kf.split(list(range(len(y_data)))))): \n","        \n","        # Sample idx\n","        start = time.time()\n","        sample_idx = np.random.choice(range(len(train_idx)), size=int(len(train_idx)*sample_frac))\n","\n","        sampled_combined = x_data[train_idx][sample_idx]\n","        labels = y_data[train_idx][sample_idx]\n","\n","        features = x_data.shape[1] if(features == 'all') else features\n","        pca = PCA(n_components=features)\n","        scalar = StandardScaler().fit(sampled_combined)\n","        standardized = scalar.transform(sampled_combined)\n","        transformed = pca.fit_transform(standardized)\n","        \n","        # Fit and time model\n","        model.fit(transformed, labels)\n","        fit_times.append(time.time() - start)\n","\n","        # Transform test data and evaluate\n","        test_transform = np.dot(scalar.transform(x_data[test_idx]), pca.components_.T)\n","        preds = model.predict(test_transform)\n","        score = accuracy_score(preds, y_data[test_idx])\n","        pred_accuracy.append(score)      \n","        \n","    print(r\"{0} FRAC  {1} POINTS PREDICTION ACCURACY: {2:.3f} $\\pm$ {3:.3f}\".format(sample_frac, len(sample_idx), np.mean(pred_accuracy), np.std(pred_accuracy)))\n","    return pred_accuracy, fit_times"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2LiBeHeayQuc","executionInfo":{"status":"aborted","timestamp":1638844785652,"user_tz":300,"elapsed":11,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["# Number of Psuedo data points\n","num_points = [0.001, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.075, 0.1, 0.125, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5]\n","num_points = [0.02, 0.03, 0.04, 0.05, 0.075, 0.1, 0.125, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5]\n","num_features = np.arange(5, 500, 20)\n","\n","results = []\n","times = []\n","for num in num_features:\n","    pred_accuracy, fit_times = do_kfold_frac_subsampled_pca(svm.SVC(kernel='linear', C=1), combined_x, combined_y, sample_frac=0.25, features=num)\n","    results.append(pred_accuracy)\n","    times.append(fit_times)\n","    \n","# Get means\n","nsub_acc_mean = np.mean(results, axis=1)\n","nsub_acc_stds = np.std(results, axis=1)\n","nsub_time_mean = np.mean(times, axis=1)\n","nsub_time_stds = np.std(times, axis=1)\n","\n","np.save(\"/content/drive/MyDrive/uci_har_dataset/results/svm_pre_sub_pca_linear_accuracy.npy\", results)\n","np.save(\"/content/drive/MyDrive/uci_har_dataset/results/svm_pre_sub_pca_linear_time.npy\", times)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d81puCRQ9dPw","executionInfo":{"status":"aborted","timestamp":1638844785652,"user_tz":300,"elapsed":11,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["fig, ax = plt.subplots()\n","ax.errorbar(nsub_time_mean, nsub_acc_mean, xerr=nsub_time_stds, yerr=nsub_acc_stds, capsize=3, zorder=0)\n","ax.scatter(nsub_time_mean, nsub_acc_mean, marker='s', s=50, edgecolor='k', linewidth=2)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"elHGc2_20cAA","executionInfo":{"status":"aborted","timestamp":1638844785652,"user_tz":300,"elapsed":11,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["fig, ax = plt.subplots()\n","\n","print(len(num_features))\n","ax.plot(num_features, pca_acc_mean)\n","ax.fill_between(num_features, pca_acc_mean+pca_acc_stds, pca_acc_mean-pca_acc_stds, alpha=0.5)\n","ax.plot(num_features, nsub_acc_mean)\n","ax.fill_between(num_features, nsub_acc_mean+nsub_acc_stds, nsub_acc_mean-nsub_acc_stds, alpha=0.5)\n","ax.plot(num_points, sub_acc_mean)\n","plt.show()\n","\n","fig, ax = plt.subplots()\n","ax.plot(num_features, pca_time_mean)\n","ax.fill_between(num_features, pca_time_mean+pca_time_stds, pca_time_mean-pca_time_stds, alpha=0.5)\n","ax.plot(num_features, nsub_time_mean)\n","ax.fill_between(num_features, nsub_time_mean+nsub_time_stds, nsub_time_mean-nsub_time_stds, alpha=0.5)\n","ax.plot(num_points, sub_time_mean)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a4X6Ah8rrx_w"},"source":["### Subsampled with MI"]},{"cell_type":"code","metadata":{"id":"se77aB6ur4pa","executionInfo":{"status":"aborted","timestamp":1638844785868,"user_tz":300,"elapsed":226,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["def do_kfold_sub_mutual_info(model, x_data, y_data, features='all', sample_frac=0.25, folds=10):\n","     \n","    # Do KFold\n","    kf = KFold(folds)\n","    \n","    # KF training\n","    pred_accuracy = []\n","    fit_times = []\n","    for idx, (train_idx, test_idx) in tqdm(enumerate(kf.split(x_data))): \n","\n","        # Sample idx\n","        start = time.time()\n","        sample_idx = np.random.choice(range(len(train_idx)), size=int(len(train_idx)*sample_frac))\n","\n","        sampled_combined = x_data[train_idx][sample_idx]\n","        labels = y_data[train_idx][sample_idx]   \n","        \n","        # Do Mutual Information Feature Extraction\n","        features = x_data.shape[1] if(features == 'all') else features\n","        fs = SelectKBest(score_func=mutual_info_classif, k=features)\n","        fs.fit(sampled_combined, labels)\n","        x_train_fs = fs.transform(sampled_combined)\n","        x_test_fs = fs.transform(x_data[test_idx])\n","\n","        # Standardize data\n","        scaler = StandardScaler().fit(x_train_fs)\n","        transformed = scaler.transform(x_train_fs)\n","        \n","        # Fit and time model\n","        model.fit(transformed, labels)\n","        fit_times.append(time.time() - start)\n","        \n","        # Transform test data and evaluate\n","\n","        preds = model.predict(scaler.transform(x_test_fs))\n","        score = accuracy_score(preds, y_data[test_idx])\n","        pred_accuracy.append(score)\n","        \n","    print(r\"{0} FEATURES PREDICTION ACCURACY: {1:.3f} $\\pm$ {2:.3f}\".format(features, np.mean(pred_accuracy), np.std(pred_accuracy)))\n","    return pred_accuracy, fit_times"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ii4wVPB8EXw","executionInfo":{"status":"aborted","timestamp":1638844785869,"user_tz":300,"elapsed":227,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["# Number of PCA Components\n","num_features = np.arange(5, 500, 20)\n","\n","results = []\n","times = []\n","for features in num_features:\n","    print(features)\n","    pred_accuracy, fit_times = do_kfold_sub_mutual_info(svm.SVC(kernel='linear', C=1), combined_x, combined_y, features=features, sample_frac=0.25)\n","    #pred_accuracy, fit_times = do_kfold_frac_subsampled_pca(svm.SVC(kernel='linear', C=1), combined_x, combined_y, sample_frac=0.25, features=num)\n","\n","    results.append(pred_accuracy)\n","    times.append(fit_times)\n","\n","# Get means\n","ml_acc_mean = np.mean(results, axis=1)\n","ml_acc_stds = np.std(results, axis=1)\n","ml_time_mean = np.mean(times, axis=1)\n","ml_time_stds = np.std(times, axis=1)\n","\n","#\"/content/drive/MyDrive/uci_har_dataset/test/X_test.txt\"\n","np.save(\"/content/drive/MyDrive/uci_har_dataset/results/svm_pre_sub_mi_linear_accuracy.npy\", results)\n","np.save(\"/content/drive/MyDrive/uci_har_dataset/results/svm_pre_sub_mi_linear_time.npy\", times)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ujwdt4_pN7xN"},"source":["## Part 3\n","- Identify the optimal number of features using feature engineering technique based on time and accuracy. "]},{"cell_type":"code","metadata":{"id":"MskzytY0N7xN","executionInfo":{"status":"aborted","timestamp":1638844785869,"user_tz":300,"elapsed":227,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["err = 0.003\n","#For PCA\n","for i in range (0,len(num_features)):\n","    if pca_acc_mean[i+1] - pca_acc_mean[i] <= err:\n","        PCA_f = i\n","        print(f'For {num_features[i]}, the accuracy is {pca_acc_mean[i]}')\n","        break\n","        \n","# For MI\n","for j in range (0,len(num_features)):\n","    if ml_acc_mean[j+1] - ml_acc_mean[j] <= err:\n","        MI_f = j\n","        print(f'For {num_features[j]}, the accuracy is {ml_acc_mean[j]}')\n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E1wBDXx1N7xN"},"source":["### From our results above, PCA generates the best accuracy for the same number of features. However, based on the time plot, MI takes less time to run than PCA.  "]},{"cell_type":"code","metadata":{"id":"2U_EEusxN7xN","executionInfo":{"status":"aborted","timestamp":1638844785869,"user_tz":300,"elapsed":227,"user":{"displayName":"Cooper Lorsung","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04276650838177250772"}}},"source":["pred_accuracy, fit_times = do_kfold_pca(svm.SVC(kernel='linear', C=1), combined_x, combined_y, features= num_features[PCA_f])\n","pred_accuracy\n","fit_times"],"execution_count":null,"outputs":[]}]}
